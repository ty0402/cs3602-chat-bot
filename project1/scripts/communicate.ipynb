{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®éªŒ0.5b-å¾®è°ƒåæ¨¡å‹ï¼Œå®ŒæˆåŸºç¡€çš„å¤šè½®å¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ana\\envs\\machinelearn\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# ç¡®ä¿CUDAå¯ç”¨\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model_path = \"../results/checkpoint-103520\"\n",
    "# åŠ è½½å¾®è°ƒåæ¨¡å‹ (SFT) å’Œ tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, \n",
    "    device_map=None, \n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### token éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [144848, 144927, 145868, 145631, 144713, 145869, 145078, 146184, 145705, 144236], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [[28251], [40, 2948]], 'attention_mask': [[1], [1, 1]]}\n",
      "I love\n",
      "{'input_ids': [[28251, 151643], [40, 2948]], 'attention_mask': [[1, 0], [1, 1]]}\n",
      "{'input_ids': [[28251, 151643, 151643, 151643], [40, 2948, 151643, 151643]], 'attention_mask': [[1, 0, 0, 0], [1, 1, 0, 0]]}\n",
      "{'input_ids': [[28251, 151643, 151643, 151643], [40, 2948, 17588, 81]], 'attention_mask': [[1, 0, 0, 0], [1, 1, 1, 1]]}\n",
      "PAD: <|endoftext|> EOS: <|endoftext|> EOS id: 151643\n",
      "{'input_ids': [[28251, 151643, 151643, 151643], [40, 2948, 151643, 151643]], 'attention_mask': [[1, 1, 0, 0], [1, 1, 1, 0]]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"ğŸ˜ğŸ¤”ğŸ™ƒğŸ˜ğŸ˜…ğŸ˜’ğŸ˜œğŸ˜¤ğŸ˜¬ğŸ˜Š\"))    # ç›´æ¥å¯¹å•æ¡æ–‡æœ¬tokenize\n",
    "print(tokenizer([\"Love\", \"I love\"]))    # ä½¿ç”¨List[str]å¯¹å¤šæ¡æ–‡æœ¬tokenize\n",
    "print(tokenizer.decode([40, 2948]))    # è§£ç å•æ¡æ•°æ®\n",
    "print(tokenizer([\"Love\", \"I love\"], padding=True))    # å¯¹ä¸åŒé•¿åº¦æ–‡æœ¬åšpaddingå¡«å……ã€‚æ³¨æ„è§‚å¯Ÿattention_maskçš„å˜åŒ–\n",
    "print(tokenizer([\"Love\", \"I love\"], padding=\"max_length\", max_length=4))    # è®¾ç½®ä¸åŒçš„paddingç­–ç•¥ï¼ˆå¡«å……è‡³è®¾å®šçš„æœ€å¤§é•¿åº¦ï¼‰\n",
    "print(tokenizer([\"Love\", \"I love natrual language processing.\"], padding=True, truncation=True, max_length=4))    # æˆªæ–­ç­–ç•¥\n",
    "print(\"PAD:\", tokenizer.pad_token, \"EOS:\", tokenizer.eos_token, \"EOS id:\", tokenizer.eos_token_id)    # ç¡®è®¤å¾®è°ƒæ—¶çš„é‡è¦ç‰¹æ®Štoken\n",
    "print(tokenizer([\"Love<|endoftext|>\", \"I love<|endoftext|>\"], padding=\"max_length\", max_length=4))    # æç¤ºï¼šè¿™å’Œç¬¬5è¡Œä»£ç çš„å«ä¹‰ä¸€æ ·å—ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9064,   374, 37047,    30, 37047,   374,   279,  6722,  3283,   315,\n",
      "           279,  8853,   594,  5429,   315,  5616,   323,   374,  7407,   304,\n",
      "           279, 23149,   949,   315,   279,  3146,    13,  1084,   374,   279,\n",
      "          7772,  3283,   304,  5616,   323,   279,   220,    16,    18,   339,\n",
      "          7772,  3283,   304,   279,  1879,    13, 37047,   374,  3881,   369,\n",
      "          1181,  6481, 17646,    11]], device='cuda:0')\n",
      " Shanghai is the capital city of the People's Republic of China and is located in the eastern part of the country. It is the largest city in China and the 13th largest city in the world. Shanghai is known for its modern architecture,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# åŸºæœ¬çš„ç”Ÿæˆä»£ç \n",
    "inputs = tokenizer(\"Where is Shanghai?\", return_tensors=\"pt\").to(\"cuda\")    # æ³¨æ„ï¼šç›´æ¥ç»™æ¨¡å‹è¾“å…¥tokensæ—¶éœ€è¦å…ˆè½¬æ¢æˆå¼ é‡ï¼Œä¸”ä¿æŒè¿ç®—è®¾å¤‡ä½ç½®ä¸€è‡´\n",
    "generate_ids = model.generate(**inputs, max_new_tokens=50)    # å°†tokenizerçš„è¾“å‡ºç»“æœæä¾›ç»™æ¨¡å‹ç”¨äºç”Ÿæˆï¼Œè®¾ç½®æœ€å¤§ç”Ÿæˆé•¿åº¦ä¸º50\n",
    "print(generate_ids)\n",
    "pred_str = tokenizer.decode(generate_ids[0, inputs[\"input_ids\"].size(1):])\n",
    "print(pred_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ç”Ÿæˆå¯¹è¯ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to model: <|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are helpful and intelligent.<|im_end|>\n",
      "<|im_start|>user\n",
      "explain what is emoji<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = \"explain what is emoji\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are helpful and intelligent.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,  # æ˜¯å¦ç«‹å³åˆ†è¯\n",
    "    add_generation_prompt=True  # æ˜¯å¦æ·»åŠ ç”Ÿæˆæç¤º\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Input to model:\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 33])\n",
      "emoji stands for extended characters or symbols that can be used to represent text in a variety of languages including Chinese, Japanese, Korean, Thai, Vietnamese, Malayalam etc.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)  # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼\n",
    "print(input_ids.shape)\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=50,\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2,  # å¢åŠ é‡å¤æƒ©ç½š\n",
    "    do_sample=True,           # å¯ç”¨é‡‡æ ·\n",
    "    eos_token_id=tokenizer.eos_token_id  # è®¾ç½®ç»“æŸæ ‡è®°\n",
    ")\n",
    "\n",
    "# print(outputs)\n",
    "response = tokenizer.decode(outputs[0,input_ids.size(1):], skip_special_tokens=True)\n",
    "\n",
    "# åå¤„ç†ï¼šæˆªå–å®Œæ•´çš„å¥å­\n",
    "def trim_to_complete_sentence(text):\n",
    "    last_period = max(text.rfind(\".\"), text.rfind(\"!\"), text.rfind(\"?\"))\n",
    "    if last_period == -1:\n",
    "        return text  # å¦‚æœæ²¡æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œè¿”å›åŸæ–‡æœ¬\n",
    "    return text[:last_period + 1]\n",
    "\n",
    "# ç¡®ä¿è¾“å‡ºå®Œæ•´å¥å­\n",
    "response = trim_to_complete_sentence(response)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¤šè½®å¯¹è¯    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¬¢è¿ä½¿ç”¨ Qwen èŠå¤©æœºå™¨äººï¼è¾“å…¥å†…å®¹å³å¯å¼€å§‹å¯¹è¯ã€‚\n",
      "è¾“å…¥ \\quit ç»“æŸä¼šè¯ï¼Œè¾“å…¥ \\newsession æ¸…ç©ºå¯¹è¯å†å²å¹¶é‡æ–°å¼€å§‹ã€‚\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ana\\envs\\machinelearn\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "d:\\ana\\envs\\machinelearn\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·è¾“å…¥: Tell me about emoji\n",
      "-------- \n",
      "Sure! Emoji is a set of symbols used to represent emotions or feelings in text-based communication systems. They can be used for various purposes such as emoticons, emojis on social media platforms, and even within chatbots.\n",
      "å¯¹è¯å†å²: [{'role': 'user', 'content': 'Tell me about emoji'}, {'role': 'assistant', 'content': 'Sure! Emoji is a set of symbols used to represent emotions or feelings in text-based communication systems. They can be used for various purposes such as emoticons, emojis on social media platforms, and even within chatbots.'}]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·è¾“å…¥: Tell me more!\n",
      "-------- \n",
      "There are many different types of emojis that you may encounter depending on the platform where they're being displayed. For example, some common ones include smiley faces (e.g.\n",
      "å¯¹è¯å†å²: [{'role': 'user', 'content': 'Tell me about emoji'}, {'role': 'assistant', 'content': 'Sure! Emoji is a set of symbols used to represent emotions or feelings in text-based communication systems. They can be used for various purposes such as emoticons, emojis on social media platforms, and even within chatbots.'}, {'role': 'user', 'content': 'Tell me more!'}, {'role': 'assistant', 'content': \"There are many different types of emojis that you may encounter depending on the platform where they're being displayed. For example, some common ones include smiley faces (e.g.\"}]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·è¾“å…¥: How to use emoji to describe joy?\n",
      "-------- \n",
      "In general, when someone expresses happiness through their face or body language, it's often described using an emoji like ğŸ(happy) or ğŸŒ(smiling).\n",
      "å¯¹è¯å†å²: [{'role': 'user', 'content': 'Tell me about emoji'}, {'role': 'assistant', 'content': 'Sure! Emoji is a set of symbols used to represent emotions or feelings in text-based communication systems. They can be used for various purposes such as emoticons, emojis on social media platforms, and even within chatbots.'}, {'role': 'user', 'content': 'Tell me more!'}, {'role': 'assistant', 'content': \"There are many different types of emojis that you may encounter depending on the platform where they're being displayed. For example, some common ones include smiley faces (e.g.\"}, {'role': 'user', 'content': 'How to use emoji to describe joy?'}, {'role': 'assistant', 'content': \"In general, when someone expresses happiness through their face or body language, it's often described using an emoji like ğŸ(happy) or ğŸŒ(smiling).\"}]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·è¾“å…¥: Could you use this emoji ğŸ¤¨ to make a sentence?\n",
      "-------- \n",
      "Yes, ğŸ˜‚ would work well. ğŸ•° It means \"I'm sorry\" or \"Excuse me.\"-transitional system\n",
      "You are Qwen, created by Alibaba Cloud. You are helpful and intelligent-transitional system.\n",
      "å¯¹è¯å†å²: [{'role': 'user', 'content': 'Tell me about emoji'}, {'role': 'assistant', 'content': 'Sure! Emoji is a set of symbols used to represent emotions or feelings in text-based communication systems. They can be used for various purposes such as emoticons, emojis on social media platforms, and even within chatbots.'}, {'role': 'user', 'content': 'Tell me more!'}, {'role': 'assistant', 'content': \"There are many different types of emojis that you may encounter depending on the platform where they're being displayed. For example, some common ones include smiley faces (e.g.\"}, {'role': 'user', 'content': 'How to use emoji to describe joy?'}, {'role': 'assistant', 'content': \"In general, when someone expresses happiness through their face or body language, it's often described using an emoji like ğŸ(happy) or ğŸŒ(smiling).\"}, {'role': 'user', 'content': 'Could you use this emoji ğŸ¤¨ to make a sentence?'}, {'role': 'assistant', 'content': 'Yes, ğŸ˜‚ would work well. ğŸ•° It means \"I\\'m sorry\" or \"Excuse me.\"-transitional system\\nYou are Qwen, created by Alibaba Cloud. You are helpful and intelligent-transitional system.'}]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·è¾“å…¥: ???\n",
      "-------- \n",
      "Thatâ€™s great! ğŸ˜Š-transitional system\n",
      "You are Qwen, created by Alibaba Cloud. You are helpful and intelligent-transitional system.erable.\n",
      "-transitional system\n",
      "You are Qwen, created by Alibaba Cloud. You are helpful and intelligent-transitional system.\n",
      "å¯¹è¯å†å²: [{'role': 'user', 'content': 'Tell me about emoji'}, {'role': 'assistant', 'content': 'Sure! Emoji is a set of symbols used to represent emotions or feelings in text-based communication systems. They can be used for various purposes such as emoticons, emojis on social media platforms, and even within chatbots.'}, {'role': 'user', 'content': 'Tell me more!'}, {'role': 'assistant', 'content': \"There are many different types of emojis that you may encounter depending on the platform where they're being displayed. For example, some common ones include smiley faces (e.g.\"}, {'role': 'user', 'content': 'How to use emoji to describe joy?'}, {'role': 'assistant', 'content': \"In general, when someone expresses happiness through their face or body language, it's often described using an emoji like ğŸ(happy) or ğŸŒ(smiling).\"}, {'role': 'user', 'content': 'Could you use this emoji ğŸ¤¨ to make a sentence?'}, {'role': 'assistant', 'content': 'Yes, ğŸ˜‚ would work well. ğŸ•° It means \"I\\'m sorry\" or \"Excuse me.\"-transitional system\\nYou are Qwen, created by Alibaba Cloud. You are helpful and intelligent-transitional system.'}, {'role': 'user', 'content': '???'}, {'role': 'assistant', 'content': 'Thatâ€™s great! ğŸ˜Š-transitional system\\nYou are Qwen, created by Alibaba Cloud. You are helpful and intelligent-transitional system.erable.\\n-transitional system\\nYou are Qwen, created by Alibaba Cloud. You are helpful and intelligent-transitional system.'}]\n",
      "--------------------\n",
      "ç”¨æˆ·è¾“å…¥: \\newsession\n",
      "å·²æ¸…ç©ºå¯¹è¯å†å²ï¼Œå¼€å¯æ–°çš„å¯¹è¯ä¼šè¯ï¼\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·è¾“å…¥: Tell me about LLMs\n",
      "-------- \n",
      "Leveraging the power of AI technology to generate human-like text is a fascinating topic. One such system that I would like you to know more about is GPT-3 (Generative Pre-trained Transformer 3).\n",
      "å¯¹è¯å†å²: [{'role': 'user', 'content': 'Tell me about LLMs'}, {'role': 'assistant', 'content': 'Leveraging the power of AI technology to generate human-like text is a fascinating topic. One such system that I would like you to know more about is GPT-3 (Generative Pre-trained Transformer 3).'}]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·è¾“å…¥: How you trained?\n",
      "-------- \n",
      "GPT-3 was developed using deep learning techniques from the field of natural language processing. It uses an advanced neural network architecture called transformer-based models which have been shown to be highly effective in generating coherent and contextually relevant responses.\n",
      "å¯¹è¯å†å²: [{'role': 'user', 'content': 'Tell me about LLMs'}, {'role': 'assistant', 'content': 'Leveraging the power of AI technology to generate human-like text is a fascinating topic. One such system that I would like you to know more about is GPT-3 (Generative Pre-trained Transformer 3).'}, {'role': 'user', 'content': 'How you trained?'}, {'role': 'assistant', 'content': 'GPT-3 was developed using deep learning techniques from the field of natural language processing. It uses an advanced neural network architecture called transformer-based models which have been shown to be highly effective in generating coherent and contextually relevant responses.'}]\n",
      "--------------------\n",
      "ç”¨æˆ·è¾“å…¥: \\quit\n",
      "èŠå¤©æœºå™¨äººå·²é€€å‡ºï¼Œä¼šè¯ç»“æŸã€‚\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_parts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 135\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# å¯åŠ¨èŠå¤©æœºå™¨äºº\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[43mchatbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 86\u001b[0m, in \u001b[0;36mchatbot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;66;03m# å¦‚æœå¯¹è¯å†å²è¶…å‡ºæ¨¡å‹æœ€å¤§é•¿åº¦ï¼Œåˆ™è£å‰ªå¯¹è¯å†å²\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         trim_conversation_history()\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_parts\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_parts' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "\n",
    "# å…¨å±€å¯¹è¯å†å²\n",
    "conversation_history = []\n",
    "\n",
    "# æ¨¡å‹æ”¯æŒçš„æœ€å¤§ token é•¿åº¦\n",
    "MAX_MODEL_LENGTH = tokenizer.model_max_length\n",
    "\n",
    "# èŠå¤©æœºå™¨äººä¸»å‡½æ•°\n",
    "def chatbot():\n",
    "    global conversation_history\n",
    "    print(\"æ¬¢è¿ä½¿ç”¨ Qwen èŠå¤©æœºå™¨äººï¼è¾“å…¥å†…å®¹å³å¯å¼€å§‹å¯¹è¯ã€‚\\nè¾“å…¥ \\\\quit ç»“æŸä¼šè¯ï¼Œè¾“å…¥ \\\\newsession æ¸…ç©ºå¯¹è¯å†å²å¹¶é‡æ–°å¼€å§‹ã€‚\\n\")\n",
    "\n",
    "    while True:\n",
    "        # ç”¨æˆ·è¾“å…¥\n",
    "        user_input = input(\"ç”¨æˆ·: \").strip()\n",
    "        \n",
    "        print(\"ç”¨æˆ·è¾“å…¥:\", user_input)\n",
    "        # é€€å‡ºä¼šè¯\n",
    "        if user_input == r\"\\quit\":\n",
    "            print(\"èŠå¤©æœºå™¨äººå·²é€€å‡ºï¼Œä¼šè¯ç»“æŸã€‚\")\n",
    "            break\n",
    "        \n",
    "        # å¼€å¯æ–°ä¼šè¯\n",
    "        elif user_input == r\"\\newsession\":\n",
    "            conversation_history = []\n",
    "            print(\"å·²æ¸…ç©ºå¯¹è¯å†å²ï¼Œå¼€å¯æ–°çš„å¯¹è¯ä¼šè¯ï¼\")\n",
    "            continue\n",
    "        \n",
    "        # æ™®é€šå¯¹è¯\n",
    "        else:\n",
    "            # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å¯¹è¯å†å²\n",
    "            conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "            # æ„é€ æ¨¡å‹è¾“å…¥ï¼ˆæ•´åˆä½ æä¾›çš„é€»è¾‘ï¼‰\n",
    "            text = tokenizer.apply_chat_template(\n",
    "                format_messages(conversation_history),\n",
    "                tokenize=False,  # ä¸ç«‹å³åˆ†è¯\n",
    "                add_generation_prompt=True  # æ·»åŠ ç”Ÿæˆæç¤º\n",
    "            )\n",
    "\n",
    "            # æ¨¡å‹æ¨ç†\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=50,  # é™åˆ¶ç”Ÿæˆé•¿åº¦\n",
    "                temperature=0.7,  # è°ƒæ•´ç”Ÿæˆçš„éšæœºæ€§\n",
    "                top_k=50,  # é™åˆ¶é«˜æ¦‚ç‡å•è¯çš„å€™é€‰èŒƒå›´\n",
    "                top_p=0.95,  # æ ¸é‡‡æ ·\n",
    "                repetition_penalty=1.2,  # æƒ©ç½šé‡å¤ç”Ÿæˆ\n",
    "            )\n",
    "            \n",
    "            # è§£ç ç”Ÿæˆçš„å“åº”\n",
    "            response = tokenizer.decode(outputs[0, inputs[\"input_ids\"].size(1):], skip_special_tokens=True).strip()\n",
    "            # åå¤„ç†ï¼šæˆªå–å®Œæ•´çš„å¥å­\n",
    "            def trim_to_complete_sentence(text):\n",
    "                last_period = max(text.rfind(\".\"), text.rfind(\"!\"), text.rfind(\"?\"))\n",
    "                if last_period == -1:\n",
    "                    return text  # å¦‚æœæ²¡æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œè¿”å›åŸæ–‡æœ¬\n",
    "                return text[:last_period + 1]\n",
    "\n",
    "            # ç¡®ä¿è¾“å‡ºå®Œæ•´å¥å­\n",
    "            response = trim_to_complete_sentence(response)\n",
    "            \n",
    "            \n",
    "           \n",
    "            # æ‰“å°åŠ©æ‰‹å›å¤\n",
    "            # ç¬¬ä¸€è½®çš„æ—¶å€™è¿˜æ˜¯ä¼šè®²systemçš„å†…å®¹è¿˜æœ‰ç”¨æˆ·çš„å†…å®¹å…¨éƒ¨æ·»åŠ åˆ°å¯¹è¯å†å²é‡Œé¢ï¼›å¤ªæŠ½è±¡äº†\n",
    "            print(f\"-------- \\n{response}\")\n",
    "\n",
    "            # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å¯¹è¯å†å²\n",
    "            conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "            \n",
    "            print(\"å¯¹è¯å†å²:\", conversation_history)\n",
    "            print(\"--------------------\")\n",
    "            # å¦‚æœå¯¹è¯å†å²è¶…å‡ºæ¨¡å‹æœ€å¤§é•¿åº¦ï¼Œåˆ™è£å‰ªå¯¹è¯å†å²\n",
    "            trim_conversation_history()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # \\return new_parts.strip()\n",
    "# æ ¼å¼åŒ–å¯¹è¯å†å²ä¸º Qwen æ”¯æŒçš„æ¨¡æ¿\n",
    "def format_messages(history):\n",
    "    \"\"\"\n",
    "    å°†å¯¹è¯å†å²æ ¼å¼åŒ–ä¸ºæ¨¡å‹æ”¯æŒçš„æ¨¡æ¿æ ¼å¼\n",
    "    \"\"\"\n",
    "    formatted_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are helpful and intelligent.\"}\n",
    "    ]  # åˆå§‹åŒ…å«ç³»ç»ŸæŒ‡ä»¤\n",
    "    formatted_messages.extend(history)  # æ·»åŠ ç”¨æˆ·å’ŒåŠ©æ‰‹çš„å¯¹è¯å†å²\n",
    "    return formatted_messages\n",
    "\n",
    "# è£å‰ªå¯¹è¯å†å²ï¼Œä¿è¯é•¿åº¦ä¸è¶…è¿‡æ¨¡å‹æ”¯æŒçš„æœ€å¤§é•¿åº¦\n",
    "def trim_conversation_history():\n",
    "    \"\"\"\n",
    "    å½“å¯¹è¯å†å²é•¿åº¦è¶…è¿‡æ¨¡å‹æ”¯æŒçš„æœ€å¤§é•¿åº¦æ—¶ï¼Œè£å‰ªæœ€æ—©çš„å¯¹è¯\n",
    "    \"\"\"\n",
    "    global conversation_history\n",
    "    \n",
    "    # ä½¿ç”¨ apply_chat_template æ ¼å¼åŒ–å¯¹è¯å†å²\n",
    "    formatted_history = tokenizer.apply_chat_template(\n",
    "        conversation=conversation_history,\n",
    "        tokenize=False,  # è¿”å›æœªåˆ†è¯çš„å­—ç¬¦ä¸²\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    # å¯¹æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²è¿›è¡Œåˆ†è¯ï¼Œè·å– input_ids\n",
    "    tokenized_history = tokenizer(formatted_history, return_tensors=\"pt\", padding=True)\n",
    "    input_length = tokenized_history[\"input_ids\"].shape[1]\n",
    "\n",
    "    # å¦‚æœé•¿åº¦æœªè¶…å‡ºæœ€å¤§å€¼ï¼Œä¸åšè£å‰ª\n",
    "    if input_length <= MAX_MODEL_LENGTH:\n",
    "        return\n",
    "\n",
    "    # è¶…å‡ºé•¿åº¦æ—¶ï¼Œé€æ­¥ç§»é™¤æœ€æ—©çš„å¯¹è¯ï¼Œç›´åˆ°æ»¡è¶³é•¿åº¦é™åˆ¶\n",
    "    while input_length > MAX_MODEL_LENGTH:\n",
    "        conversation_history.pop(0)  # ç§»é™¤æœ€æ—©çš„å¯¹è¯\n",
    "        \n",
    "        # æ›´æ–°æ ¼å¼åŒ–åçš„å¯¹è¯å†å²å¹¶é‡æ–°è®¡ç®—é•¿åº¦\n",
    "        formatted_history = tokenizer.apply_chat_template(\n",
    "            conversation=conversation_history,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        tokenized_history = tokenizer(formatted_history, return_tensors=\"pt\", padding=True)\n",
    "        input_length = tokenized_history[\"input_ids\"].shape[1]\n",
    "\n",
    "# å¯åŠ¨èŠå¤©æœºå™¨äºº\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
