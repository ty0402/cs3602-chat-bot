{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测SFT回答正确而PLM回答错误的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:49: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Windows\\Temp\\ipykernel_32132\\1058105397.py:49: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  sft_folder_path = \"SFT_basic\\predictions\\checkpoint-103520_hf\"  # 替换为SFT文件夹路径\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评测数据集：lukaemon_mmlu_us_foreign_policy\n",
      "PLM回答错误但SFT回答正确的题目序号：['7', '9', '12', '98']\n",
      "评测数据集：lukaemon_mmlu_human_sexuality\n",
      "PLM回答错误但SFT回答正确的题目序号：['18', '21', '27', '31', '54']\n",
      "评测数据集：lukaemon_mmlu_high_school_computer_science\n",
      "PLM回答错误但SFT回答正确的题目序号：['9', '50', '60', '65', '68']\n",
      "评测数据集：lukaemon_mmlu_college_medicine\n",
      "PLM回答错误但SFT回答正确的题目序号：['13', '26', '37', '49', '88', '89', '98', '112', '114', '146', '164']\n",
      "评测数据集：lukaemon_mmlu_jurisprudence\n",
      "PLM回答错误但SFT回答正确的题目序号：['1', '9', '34', '46', '67', '78', '83']\n",
      "评测数据集：hellaswag\n",
      "PLM回答错误但SFT回答正确的题目序号：['2', '35', '83', '89', '97', '105', '112', '113', '144', '171', '174', '176', '179', '215', '228', '242', '269', '323', '343', '363', '364', '376', '377', '378', '383', '386', '397', '440', '445', '477', '487', '501', '521', '535', '563', '564', '570', '579', '595', '636', '637', '641', '651', '739', '740', '759', '762', '770', '782', '794', '813', '823', '830', '848', '856', '873', '875', '890', '903', '944', '946', '957', '995', '1011', '1020', '1039', '1066', '1081', '1104', '1107', '1158', '1166', '1172', '1196', '1220', '1228', '1245', '1254', '1255', '1291', '1292', '1311', '1388', '1428', '1473', '1483', '1505', '1515', '1522', '1557', '1560', '1581', '1600', '1616', '1621', '1644', '1674', '1695', '1714', '1736', '1770', '1825', '1831', '1836', '1837', '1881', '1906', '1953', '1960', '1961', '1962', '1974', '1988', '1989', '2057', '2080', '2085', '2093', '2098', '2104', '2109', '2117', '2132', '2146', '2150', '2172', '2178', '2179', '2213', '2251', '2253', '2268', '2272', '2293', '2304', '2309', '2318', '2328', '2351', '2357', '2358', '2372', '2380', '2402', '2438', '2441', '2446', '2470', '2514', '2521', '2530', '2546', '2562', '2588', '2602', '2613', '2617', '2649', '2698', '2746', '2841', '2845', '2871', '2884', '2892', '2905', '2926', '2932', '2958', '2961', '2963', '3023', '3049', '3052', '3056', '3067', '3081', '3143', '3146', '3171', '3187', '3199', '3228', '3239', '3242', '3246', '3282', '3314', '3323', '3330', '3338', '3351', '3354', '3410', '3438', '3514', '3515', '3554', '3593', '3596', '3639', '3646', '3648', '3681', '3718', '3724', '3755', '3829', '3842', '3850', '3853', '3887', '3888', '3889', '3894', '3958', '3981', '3983', '4006', '4007', '4020', '4103', '4137', '4141', '4163', '4187', '4228', '4231', '4253', '4259', '4275', '4280', '4362', '4385', '4448', '4452', '4509', '4515', '4516', '4518', '4531', '4572', '4575', '4580', '4639', '4660', '4661', '4682', '4703', '4710', '4732', '4740', '4755', '4777', '4805', '4821', '4831', '4842', '4863', '4864', '4901', '4904', '4909', '4934', '4945', '4961', '4966', '4972', '4989', '4996', '5025', '5045', '5089', '5101', '5105', '5129', '5150', '5170', '5211', '5223', '5302', '5303', '5330', '5338', '5361', '5423', '5456', '5467', '5488', '5539', '5541', '5561', '5585', '5587', '5593', '5664', '5689', '5696', '5708', '5734', '5740', '5763', '5792', '5825', '5830', '5837', '5892', '5902', '5912', '5936', '5943', '5965', '5966', '5977', '6042', '6061', '6073', '6084', '6094', '6120', '6194', '6235', '6236', '6269', '6276', '6369', '6372', '6374', '6375', '6378', '6382', '6390', '6415', '6450', '6473', '6489', '6508', '6529', '6544', '6563', '6568', '6663', '6715', '6726', '6743', '6816', '6826', '6835', '6851', '6856', '6875', '6881', '6910', '6939', '6945', '6946', '6971', '6981', '7010', '7017', '7053', '7089', '7102', '7115', '7131', '7228', '7235', '7261', '7267', '7413', '7462', '7465', '7477', '7498', '7502', '7531', '7549', '7553', '7592', '7599', '7625', '7673', '7687', '7710', '7727', '7747', '7754', '7762', '7771', '7775', '7799', '7816', '7819', '7828', '7881', '7942', '7959', '7971', '7985', '8014', '8023', '8078', '8098', '8104', '8115', '8122', '8135', '8148', '8165', '8206', '8227', '8247', '8258', '8276', '8292', '8314', '8324', '8349', '8357', '8363', '8385', '8415', '8416', '8464', '8469', '8486', '8530', '8547', '8583', '8586', '8614', '8654', '8666', '8674', '8684', '8690', '8709', '8717', '8719', '8740', '8819', '8835', '8837', '8848', '8860', '8916', '8979', '8988', '8997', '9002', '9010', '9013', '9018', '9068', '9110', '9117', '9141', '9155', '9166', '9191', '9196', '9210', '9214', '9237', '9254', '9256', '9298', '9311', '9313', '9321', '9324', '9353', '9362', '9394', '9457', '9485', '9508', '9529', '9547', '9564', '9581', '9588', '9600', '9606', '9609', '9612', '9621', '9633', '9652', '9655', '9710', '9746', '9782', '9795', '9796', '9808', '9819', '9868', '9908', '9917', '9923', '9929', '9954', '9955', '9958', '9996', '10033']\n",
      "评测数据集：lukaemon_mmlu_clinical_knowledge\n",
      "PLM回答错误但SFT回答正确的题目序号：['4', '11', '36', '59', '83', '108', '112', '132', '146', '147', '169', '198', '211', '215', '220', '251', '254', '258', '261', '264']\n",
      "评测数据集：lukaemon_mmlu_global_facts\n",
      "PLM回答错误但SFT回答正确的题目序号：['6', '19', '24', '29', '34', '58', '74', '92', '95', '97', '99']\n",
      "评测数据集：lukaemon_mmlu_international_law\n",
      "PLM回答错误但SFT回答正确的题目序号：['0', '22', '25', '47', '50', '62', '76', '87']\n",
      "评测数据集：lukaemon_mmlu_abstract_algebra\n",
      "PLM回答错误但SFT回答正确的题目序号：['21', '32', '37', '69', '71', '82']\n",
      "评测数据集：ARC-c-test\n",
      "PLM回答错误但SFT回答正确的题目序号：['3', '33', '38', '46', '48', '49', '56', '71', '118', '132', '149', '150', '154', '187', '213', '217', '219', '233', '251', '260', '269', '315', '321', '327', '380', '385', '386', '412', '472', '473', '495', '525', '529', '557', '562', '573', '602', '612', '631', '634', '637', '649', '662', '680', '687', '725', '733', '749', '768', '779', '780', '821', '822', '828', '830', '836', '840', '844', '850', '858', '885', '887', '907', '909', '930', '936', '954', '963', '965', '980', '1004', '1007', '1029', '1056', '1061', '1065', '1091', '1101', '1107', '1113', '1119', '1155', '1163']\n",
      "评测数据集：lukaemon_mmlu_astronomy\n",
      "PLM回答错误但SFT回答正确的题目序号：['8', '28', '40', '51', '66', '71', '93', '107', '111', '116']\n",
      "评测数据集：lukaemon_mmlu_management\n",
      "PLM回答错误但SFT回答正确的题目序号：['4', '7', '29', '38', '48', '55', '56', '82', '99']\n",
      "评测数据集：lukaemon_mmlu_professional_accounting\n",
      "PLM回答错误但SFT回答正确的题目序号：['16', '55', '56', '57', '59', '67', '73', '102', '103', '133', '136', '142', '159', '170', '179', '188', '198', '214', '235', '239', '243', '247', '255', '264', '269', '277']\n",
      "评测数据集：lukaemon_mmlu_virology\n",
      "PLM回答错误但SFT回答正确的题目序号：['44', '52', '67', '73', '109', '126', '161', '164']\n",
      "评测数据集：lukaemon_mmlu_high_school_physics\n",
      "PLM回答错误但SFT回答正确的题目序号：['41', '70', '75', '96', '103', '120']\n",
      "评测数据集：lukaemon_mmlu_professional_psychology\n",
      "PLM回答错误但SFT回答正确的题目序号：['57', '69', '86', '96', '125', '127', '130', '132', '175', '262', '270', '287', '300', '322', '328', '354', '433', '445', '449', '481', '485', '494', '514', '526', '545', '557', '566', '595', '603']\n",
      "评测数据集：lukaemon_mmlu_high_school_psychology\n",
      "PLM回答错误但SFT回答正确的题目序号：['14', '94', '119', '137', '156', '159', '161', '178', '182', '206', '211', '213', '222', '224', '226', '247', '268', '279', '308', '311', '318', '319', '354', '363', '372', '392', '394', '404', '414', '444', '453', '471', '503', '510']\n",
      "评测数据集：lukaemon_mmlu_nutrition\n",
      "PLM回答错误但SFT回答正确的题目序号：['6', '27', '71', '75', '84', '85', '106', '109', '117', '124', '151', '173', '188', '207', '217', '253', '272', '275', '280', '291', '305']\n",
      "评测数据集：lukaemon_mmlu_college_computer_science\n",
      "PLM回答错误但SFT回答正确的题目序号：['0', '32', '99']\n",
      "评测数据集：lukaemon_mmlu_high_school_microeconomics\n",
      "PLM回答错误但SFT回答正确的题目序号：['34', '54', '71', '78', '134', '144', '149', '199', '210', '220', '233']\n",
      "评测数据集：lukaemon_mmlu_logical_fallacies\n",
      "PLM回答错误但SFT回答正确的题目序号：['12', '17', '18', '30', '50', '62', '91', '101', '102', '135', '144', '160']\n",
      "评测数据集：lukaemon_mmlu_conceptual_physics\n",
      "PLM回答错误但SFT回答正确的题目序号：['16', '26', '30', '42', '44', '94', '120', '126', '127', '153', '181']\n",
      "评测数据集：lukaemon_mmlu_high_school_statistics\n",
      "PLM回答错误但SFT回答正确的题目序号：['0', '6', '20', '55', '79', '99', '105', '113', '116', '127', '128', '142', '148', '163', '172', '173', '193', '199', '210']\n",
      "评测数据集：lukaemon_mmlu_sociology\n",
      "PLM回答错误但SFT回答正确的题目序号：['30', '59', '79', '91', '122', '127', '170', '184']\n",
      "评测数据集：lukaemon_mmlu_high_school_mathematics\n",
      "PLM回答错误但SFT回答正确的题目序号：['14', '22', '24', '30', '63', '83', '84', '88', '94', '104', '110', '122', '124', '140', '144', '156', '181', '202', '205', '210', '211', '220', '234', '242', '246', '250', '260']\n",
      "评测数据集：lukaemon_mmlu_medical_genetics\n",
      "PLM回答错误但SFT回答正确的题目序号：['3', '10', '35', '46', '81']\n",
      "评测数据集：lukaemon_mmlu_elementary_mathematics\n",
      "PLM回答错误但SFT回答正确的题目序号：['8', '13', '26', '27', '46', '48', '52', '56', '60', '66', '75', '83', '105', '131', '154', '163', '199', '208', '209', '219', '222', '238', '248', '254', '257', '260', '265', '276', '293', '299', '309', '317', '331', '341', '359', '360', '373']\n",
      "评测数据集：lukaemon_mmlu_professional_medicine\n",
      "PLM回答错误但SFT回答正确的题目序号：['14', '50', '61', '69', '70', '126', '127', '135', '146', '162', '170', '179', '188', '212', '247', '262']\n",
      "评测数据集：lukaemon_mmlu_public_relations\n",
      "PLM回答错误但SFT回答正确的题目序号：['17', '26', '41', '45', '56', '59', '63', '64', '67', '80', '87', '106']\n",
      "评测数据集：lukaemon_mmlu_high_school_chemistry\n",
      "PLM回答错误但SFT回答正确的题目序号：['5', '10', '26', '28', '39', '53', '58', '65', '115', '123', '126', '129', '152', '169', '181', '201']\n",
      "评测数据集：lukaemon_mmlu_high_school_us_history\n",
      "PLM回答错误但SFT回答正确的题目序号：['0', '18', '22', '39', '50', '55', '84', '91', '112', '146', '157', '165', '195']\n",
      "评测数据集：lukaemon_mmlu_professional_law\n",
      "PLM回答错误但SFT回答正确的题目序号：['14', '20', '25', '30', '40', '56', '78', '83', '134', '178', '212', '218', '245', '267', '340', '438', '480', '524', '540', '551', '577', '600', '616', '659', '684', '714', '728', '736', '743', '788', '835', '852', '870', '873', '893', '930', '1023', '1026', '1044', '1046', '1070', '1086', '1088', '1096', '1101', '1106', '1141', '1147', '1182', '1291', '1307', '1312', '1339', '1354', '1367', '1371', '1415', '1437', '1455', '1456', '1470', '1494', '1505', '1525', '1528']\n",
      "评测数据集：ARC-e\n",
      "PLM回答错误但SFT回答正确的题目序号：['12', '22', '93', '102', '104', '128', '132', '134', '155', '159', '160', '162', '200', '216', '219', '228', '230', '235', '241', '248', '258', '280', '281', '283', '290', '294', '306', '314', '326', '329', '381', '391', '405', '415', '417', '420', '438', '444', '445', '446', '448', '457', '460', '469', '471', '474', '476', '513', '525', '528', '536', '547', '558', '559', '562']\n",
      "评测数据集：lukaemon_mmlu_econometrics\n",
      "PLM回答错误但SFT回答正确的题目序号：['18', '28', '78', '80', '111']\n",
      "评测数据集：lukaemon_mmlu_security_studies\n",
      "PLM回答错误但SFT回答正确的题目序号：['114', '115', '136', '154', '164', '172', '176', '189', '193', '194', '199', '229']\n",
      "评测数据集：lukaemon_mmlu_electrical_engineering\n",
      "PLM回答错误但SFT回答正确的题目序号：['46', '108', '120', '136']\n",
      "评测数据集：lukaemon_mmlu_business_ethics\n",
      "PLM回答错误但SFT回答正确的题目序号：['2', '17', '38']\n",
      "评测数据集：lukaemon_mmlu_college_chemistry\n",
      "PLM回答错误但SFT回答正确的题目序号：['40', '47', '55', '75', '82', '85']\n",
      "评测数据集：lukaemon_mmlu_college_physics\n",
      "PLM回答错误但SFT回答正确的题目序号：['10', '26', '49', '72', '76', '87', '95']\n",
      "评测数据集：lukaemon_mmlu_computer_security\n",
      "PLM回答错误但SFT回答正确的题目序号：['16', '22', '77']\n",
      "评测数据集：lukaemon_mmlu_philosophy\n",
      "PLM回答错误但SFT回答正确的题目序号：['2', '70', '97', '99', '116', '168', '170', '183', '219', '231', '232', '236', '240', '254', '300']\n",
      "评测数据集：lukaemon_mmlu_machine_learning\n",
      "PLM回答错误但SFT回答正确的题目序号：['40', '66', '105', '108']\n",
      "评测数据集：lukaemon_mmlu_prehistory\n",
      "PLM回答错误但SFT回答正确的题目序号：['0', '9', '14', '25', '31', '38', '54', '70', '79', '85', '86', '92', '142', '149', '170', '226', '228', '229', '242', '251', '255', '272', '299']\n",
      "评测数据集：lukaemon_mmlu_anatomy\n",
      "PLM回答错误但SFT回答正确的题目序号：['7', '30', '32', '53', '72', '88', '97', '133']\n",
      "评测数据集：lukaemon_mmlu_high_school_government_and_politics\n",
      "PLM回答错误但SFT回答正确的题目序号：['7', '81', '124', '174', '181']\n",
      "评测数据集：lukaemon_mmlu_college_biology\n",
      "PLM回答错误但SFT回答正确的题目序号：['0', '40', '41', '91', '104', '110', '143']\n",
      "评测数据集：lukaemon_mmlu_high_school_european_history\n",
      "PLM回答错误但SFT回答正确的题目序号：['49', '126', '132', '139', '142']\n",
      "评测数据集：lukaemon_mmlu_human_aging\n",
      "PLM回答错误但SFT回答正确的题目序号：['1', '17', '30', '40', '47', '57', '58', '67', '107', '132', '162', '168', '178', '193', '204']\n",
      "评测数据集：lukaemon_mmlu_high_school_world_history\n",
      "PLM回答错误但SFT回答正确的题目序号：['43', '45', '51', '66', '72', '74', '81', '109', '124', '153', '194']\n",
      "评测数据集：lukaemon_mmlu_high_school_biology\n",
      "PLM回答错误但SFT回答正确的题目序号：['21', '36', '72', '79', '82', '100', '135', '160', '175', '180', '213', '214', '238', '249', '252', '266', '275', '278', '280', '281', '298', '301']\n",
      "评测数据集：lukaemon_mmlu_high_school_macroeconomics\n",
      "PLM回答错误但SFT回答正确的题目序号：['13', '15', '23', '38', '45', '55', '101', '128', '135', '144', '150', '168', '173', '198', '238', '278', '298', '299', '325', '328', '385']\n",
      "评测数据集：lukaemon_mmlu_world_religions\n",
      "PLM回答错误但SFT回答正确的题目序号：['2', '51', '70', '103', '151', '169']\n",
      "评测数据集：lukaemon_mmlu_marketing\n",
      "PLM回答错误但SFT回答正确的题目序号：['13', '50', '162', '183', '194', '198', '203', '212', '213']\n",
      "评测数据集：lukaemon_mmlu_college_mathematics\n",
      "PLM回答错误但SFT回答正确的题目序号：['21', '25', '73', '80']\n",
      "评测数据集：lukaemon_mmlu_formal_logic\n",
      "PLM回答错误但SFT回答正确的题目序号：['6', '9', '14', '16', '22', '46', '48', '51', '53', '65', '87', '93', '95', '114', '122']\n",
      "评测数据集：lukaemon_mmlu_moral_disputes\n",
      "PLM回答错误但SFT回答正确的题目序号：['12', '13', '25', '39', '55', '67', '79', '86', '90', '146', '178', '195', '210', '225', '246', '274', '294']\n",
      "评测数据集：lukaemon_mmlu_high_school_geography\n",
      "PLM回答错误但SFT回答正确的题目序号：['38', '64', '75', '88', '89', '97', '121', '152', '156', '158']\n",
      "评测数据集：lukaemon_mmlu_miscellaneous\n",
      "PLM回答错误但SFT回答正确的题目序号：['2', '17', '20', '29', '31', '45', '69', '75', '102', '103', '114', '118', '119', '122', '129', '138', '141', '152', '158', '171', '195', '210', '214', '250', '257', '275', '287', '298', '303', '352', '357', '384', '392', '449', '460', '463', '464', '519', '541', '551', '586', '647', '669', '686', '689', '713', '738', '746', '750']\n",
      "评测数据集：BoolQ\n",
      "PLM回答错误但SFT回答正确的题目序号：['5', '8', '44', '71', '99', '115', '128', '138', '146', '150', '154', '159', '183', '190', '192', '198', '234', '250', '257', '260', '273', '293', '300', '304', '306', '310', '322', '340', '347', '384', '388', '400', '402', '417', '427', '450', '460', '480', '520', '561', '563', '564', '565', '572', '593', '622', '635', '656', '681', '712', '716', '733', '749', '780', '790', '801', '804', '823', '825', '826', '853', '854', '879', '890', '900', '901', '929', '945', '969', '979', '1008', '1015', '1055', '1063', '1089', '1099', '1149', '1153', '1194', '1195', '1205', '1214', '1216', '1226', '1227', '1239', '1268', '1289', '1296', '1309', '1323', '1325', '1347', '1365', '1377', '1380', '1407', '1419', '1433', '1435', '1451', '1483', '1487', '1492', '1509', '1533', '1547', '1558', '1559', '1565', '1573', '1602', '1612', '1625', '1629', '1649', '1653', '1655', '1662', '1679', '1691', '1705', '1736', '1791', '1809', '1833', '1837', '1847', '1853', '1856', '1867', '1870', '1878', '1882', '1890', '1967', '1977', '2006', '2017', '2028', '2047', '2048', '2058', '2066', '2080', '2099', '2100', '2146', '2148', '2165', '2184', '2192', '2197', '2200', '2201', '2226', '2256', '2281', '2283', '2295', '2331', '2361', '2375', '2379', '2395', '2401', '2414', '2430', '2434', '2451', '2457', '2482', '2506', '2511', '2520', '2527', '2548', '2556', '2562', '2567', '2578', '2582', '2589', '2591', '2621', '2639', '2680', '2691', '2700', '2721', '2768', '2778', '2805', '2829', '2836', '2854', '2869', '2873', '2885', '2892', '2901', '2921', '2940', '2942', '2947', '2961', '2987', '2997', '3013', '3039', '3045', '3067', '3073', '3082', '3087', '3090', '3155', '3164', '3210', '3211', '3221', '3234', '3256', '3260']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def compare_sft_plm_results(sft_folder, plm_folder):\n",
    "    \"\"\"\n",
    "    比较SFT和PLM文件夹下相同评测数据集的JSON文件，找出PLM回答错误而SFT回答正确的题目。\n",
    "    \n",
    "    Args:\n",
    "        sft_folder (str): SFT结果文件夹路径。\n",
    "        plm_folder (str): PLM结果文件夹路径。\n",
    "    \n",
    "    Returns:\n",
    "        dict: 错误统计结果，格式为 {评测数据集: [题目序号列表]}\n",
    "    \"\"\"\n",
    "    # 获取SFT和PLM文件夹中所有JSON文件\n",
    "    sft_files = {os.path.splitext(f)[0]: os.path.join(sft_folder, f) for f in os.listdir(sft_folder) if f.endswith('.json')}\n",
    "    plm_files = {os.path.splitext(f)[0]: os.path.join(plm_folder, f) for f in os.listdir(plm_folder) if f.endswith('.json')}\n",
    "    \n",
    "    # 找到两者都有的评测数据集\n",
    "    common_datasets = set(sft_files.keys()).intersection(set(plm_files.keys()))\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for dataset in common_datasets:\n",
    "        # 加载SFT和PLM的JSON文件\n",
    "        with open(sft_files[dataset], 'r', encoding='utf-8') as f:\n",
    "            sft_data = json.load(f)\n",
    "        with open(plm_files[dataset], 'r', encoding='utf-8') as f:\n",
    "            plm_data = json.load(f)\n",
    "        \n",
    "        # 遍历每个题目，找到PLM回答错误但SFT回答正确的题目序号\n",
    "        incorrect_but_correct_by_sft = []\n",
    "        for idx in sft_data.keys():  # 遍历题目编号\n",
    "            sft_item = sft_data[idx]\n",
    "            plm_item = plm_data[idx]\n",
    "            \n",
    "            # 比较预测结果\n",
    "            if plm_item['prediction'] != plm_item['gold'] and sft_item['prediction'] == sft_item['gold']:\n",
    "                incorrect_but_correct_by_sft.append(idx)\n",
    "        \n",
    "        # 如果有这样的题目，将其记录下来\n",
    "        if incorrect_but_correct_by_sft:\n",
    "            results[dataset] = incorrect_but_correct_by_sft\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "sft_folder_path = \"SFT_basic\\predictions\\checkpoint-103520_hf\"  # 替换为SFT文件夹路径\n",
    "plm_folder_path = \"PLM/predictions/qwen2.5_hf\"  # 替换为PLM文件夹路径\n",
    "\n",
    "comparison_results = compare_sft_plm_results(sft_folder_path, plm_folder_path)\n",
    "\n",
    "# 输出结果\n",
    "if comparison_results:\n",
    "    for dataset, indices in comparison_results.items():\n",
    "        print(f\"评测数据集：{dataset}\")\n",
    "        print(f\"PLM回答错误但SFT回答正确的题目序号：{indices}\")\n",
    "else:\n",
    "    print(\"未发现PLM回答错误但SFT回答正确的题目。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提升最多的前五个任务:\n",
      "                            dataset  acc improvement\n",
      "40       lukaemon_mmlu_formal_logic             9.52\n",
      "11       lukaemon_mmlu_global_facts             6.00\n",
      "12         lukaemon_mmlu_management             5.82\n",
      "63                       ARC-c-test             5.66\n",
      "1   lukaemon_mmlu_college_chemistry             5.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('summary_all.csv')\n",
    "\n",
    "# 计算每一行中 `1e_2epoch_hf` 列比 `qwen2.5_hf` 列的提升\n",
    "df['acc improvement'] = df['1e_2epoch_hf'] - df['qwen2.5_hf']\n",
    "\n",
    "# 找出提升最多的前五个任务\n",
    "top5_tasks = df.nlargest(5, 'acc improvement')\n",
    "\n",
    "# 打印结果\n",
    "print(\"提升最多的前五个任务:\")\n",
    "print(top5_tasks[['dataset',  'acc improvement']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPL比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:24: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\h'\n",
      "C:\\Windows\\Temp\\ipykernel_32132\\2506592066.py:24: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  SFT_file_path = 'SFT_basic\\predictions\\checkpoint-103520_hf\\hellaswag.json'\n",
      "C:\\Windows\\Temp\\ipykernel_32132\\2506592066.py:25: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  PLM_file_path = 'PLM/predictions/qwen2.5_hf\\hellaswag.json'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT 文件中 PPL 的平均值: 3.684484735589646\n",
      "PLM文件中 PPL 的平均值: 3.2348220552371525\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_ppl_from_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    ppls = []\n",
    "    for key, value in data.items():\n",
    "        for label in ['label: 0', 'label: 1', 'label: 2', 'label: 3']:\n",
    "            if label in value:\n",
    "                ppls.append(value[label]['PPL'])\n",
    "    return ppls\n",
    "\n",
    "def calculate_average_ppl(file_path):\n",
    "    ppls = extract_ppl_from_json(file_path)\n",
    "    \n",
    "    if ppls:\n",
    "        average_ppl = sum(ppls) / len(ppls)\n",
    "        return average_ppl\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 指定 JSON 文件的路径\n",
    "SFT_file_path = 'SFT_basic\\predictions\\checkpoint-103520_hf\\hellaswag.json'\n",
    "PLM_file_path = 'PLM/predictions/qwen2.5_hf\\hellaswag.json'\n",
    "# 计算平均 PPL\n",
    "average_ppl_1 = calculate_average_ppl(SFT_file_path)\n",
    "\n",
    "if average_ppl_1 is not None:\n",
    "    print(f\"SFT 文件中 PPL 的平均值: {average_ppl_1}\")\n",
    "else:\n",
    "    print(\"未找到任何 PPL 值。\")\n",
    "    \n",
    "average_ppl_2 = calculate_average_ppl(PLM_file_path)\n",
    "\n",
    "if average_ppl_2 is not None:\n",
    "    print(f\"PLM文件中 PPL 的平均值: {average_ppl_2}\")\n",
    "else:\n",
    "    print(\"未找到任何 PPL 值。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
